# Hadoop-and-Spark-Project

# Hadoop project on Stack Overflow data (Enterprise asset data 80 GB file)

Extracted and imported the file into HDFS. Used Pig XML loader to load and read the xml file and stored it again in HDFS. Created a table for the in Hive and loaded the data. Created dynamic partitions based on dates and analyzed the data using Pig and hive. Used Sqoop import/export to load the output back to HDFS and vice versa.

# Predict loan repayment abilities of customers in an Insurance company (Enterprise asset data) in scala using spark SQL and spark core

Built spark session, spark context and created case class to import the data from csv to rdd. Used Pyspark to analyze and visualize the data. Used Logistic regression and Random Forest classifiers (in Scala) to predict the probabilities of the target. Tried improving the accuracy using hyperparameter tuning.
